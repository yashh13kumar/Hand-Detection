{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffe9acd-1269-4530-adef-bf4d93ceca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HAND DETECTION CODE \n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "class HandDetector:\n",
    "    def __init__(self, max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5): #The __init__ method initializes an instance of the \n",
    "        #HandDetector class with default parameters for detecting hands and setting up drawing specifications.\n",
    "        \n",
    "        \n",
    "        self.max_num_hands = max_num_hands\n",
    "        self.min_detection_confidence = min_detection_confidence\n",
    "        self.min_tracking_confidence = min_tracking_confidence   #Stores the input parameters as instance variables for later use within the class methods.\n",
    "        \n",
    "        self.mp_hands = mp.solutions.hands #Initializes the MediaPipe hands module, which provides hand detection and tracking functionality.\n",
    "\n",
    "        self.hands = self.mp_hands.Hands(static_image_mode = False,\n",
    "                                         max_num_hands=self.max_num_hands, \n",
    "                                         min_detection_confidence=self.min_detection_confidence, \n",
    "                                         min_tracking_confidence=self.min_tracking_confidence)\n",
    "        \n",
    "        self.mp_drawing = mp.solutions.drawing_utils #Initializes the MediaPipe drawing utilities module, which provides functions for drawing landmarks and connections on the image.\n",
    "        \n",
    "        self.landmark_spec = self.mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2)  # Red landmarks\n",
    "        self.connection_spec = self.mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2)  # Blue connections\n",
    "\n",
    "    def findHands(self, image, draw=True):\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert the frame to RGB\n",
    "        self.results = self.hands.process(image_rgb)  # Process the frame and find hands\n",
    "\n",
    "        if self.results.multi_hand_landmarks: #contains the landmark data for all detected hands. If this attribute is not None, it means that hands have been detected.\n",
    "            for hand_landmarks in self.results.multi_hand_landmarks:\n",
    "                \n",
    "                if draw:      #If the draw flag is True, it draws the landmarks and connections using the MediaPipe drawing utilities.\n",
    "                    self.mp_drawing.draw_landmarks(    #uses the MediaPipe drawing utilities\n",
    "                        image, hand_landmarks, self.mp_hands.HAND_CONNECTIONS, self.landmark_spec, self.connection_spec)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def findPosition(self, image, draw=True):\n",
    "        all_hand_positions = []\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for handNo, hand_landmarks in enumerate(self.results.multi_hand_landmarks):\n",
    "                hand_positions = []\n",
    "                for id, lm in enumerate(hand_landmarks.landmark): #provides both the index (id) and the landmark object (lm) for each landmark.\n",
    "                    h, w, c = image.shape   #height (h), width (w), and number of color channels (c) \n",
    "                    cx, cy = int(lm.x * w), int(lm.y * h)  #Converts the normalized coordinates (lm.x, lm.y) to pixel coordinates\n",
    "                    hand_positions.append([id, cx, cy, lm.z]) #id: Landmark index , cx: X-coordinate in pixels , cy: Y-coordinate in pixels , lm.z: Z-coordinate (depth) in normalized space\n",
    "\n",
    "                    if draw:\n",
    "                        cv2.circle(image, (cx, cy), 5, (255, 0, 0), cv2.FILLED)\n",
    "                all_hand_positions.append(hand_positions)  #Appends the hand_positions list (containing all landmark positions for the current hand) to all_hand_positions\n",
    "        return all_hand_positions\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video capture\")\n",
    "        exit()\n",
    "\n",
    "    detector = HandDetector()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture frame from the camera.\")\n",
    "            break\n",
    "\n",
    "        frame_flipped = cv2.flip(frame, 1)  # Flip the frame horizontally\n",
    "\n",
    "        frame_flipped = detector.findHands(frame_flipped)\n",
    "        hand_positions = detector.findPosition(frame_flipped)\n",
    "\n",
    "        # Display the frame \n",
    "        cv2.imshow(\"Image\", frame_flipped)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
